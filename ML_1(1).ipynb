{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lSw8IwBPEam",
        "outputId": "ddfe9ee9-19fd-4122-a5e0-7ff5b0421308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EVALUATE_ONLY = True\n",
        "TEST_ON_LARGE_DATASET = True\n",
        "TISSUE_CLASSES = ('ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM')\n",
        "DATASETS_LINKS = {\n",
        "    'train': '1XtQzVQ5XbrfxpLHJuL0XBGJ5U7CS-cLi',\n",
        "    'train_small': '1qd45xXfDwdZjktLFwQb-et-mAaFeCzOR',\n",
        "    'train_tiny': '1I-2ZOuXLd4QwhZQQltp817Kn3J0Xgbui',\n",
        "    'test': '1RfPou3pFKpuHDJZ-D9XDFzgvwpUBFlDr',\n",
        "    'test_small': '1wbRsog0n7uGlHIPGLhyN-PMeT2kdQ2lI',\n",
        "    'test_tiny': '1viiB0s041CNsAK4itvX8PnYthJ-MDnQc'\n",
        "}"
      ],
      "metadata": {
        "id": "caei8WmpPtgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import gdown"
      ],
      "metadata": {
        "id": "A70_U7ZrQxzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/train.npz'\n",
        "test_data_path = '/content/drive/MyDrive/test.npz'\n",
        "\n",
        "train_data = np.load(train_data_path)\n",
        "test_data = np.load(test_data_path)\n",
        "\n",
        "X_train, y_train = train_data['data'], train_data['labels']\n",
        "X_test, y_test = test_data['data'], test_data['labels']\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "input_shape = (64, 64, X_train.shape[-1])\n",
        "X_train_resized = np.array([tf.image.resize(img, input_shape[:2]).numpy() for img in X_train])\n",
        "X_test_resized = np.array([tf.image.resize(img, input_shape[:2]).numpy() for img in X_test])\n",
        "\n",
        "X_train_resized = X_train_resized / 255.0\n",
        "X_test_resized = X_test_resized / 255.0\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train_resized)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(y_train)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_resized, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model.fit(datagen.flow(X_train_final, y_train_final, batch_size=32),\n",
        "                    epochs=50,\n",
        "                    validation_data=datagen.flow(X_val, y_val, batch_size=64),\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n",
        "#оценка\n",
        "test_loss, test_accuracy = model.evaluate(X_test_resized, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "model.save('CNN_or_somth.h5')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "djkiudKTvTEI",
        "outputId": "6124727e-8559-4b49-cda5-621b34a62c2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train data shape: (18000, 224, 224, 3) (18000,)\n",
            "Test data shape: (4500, 224, 224, 3) (4500,)\n",
            "Epoch 1/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 456ms/step - accuracy: 0.4256 - loss: 2.0043 - val_accuracy: 0.2197 - val_loss: 8.9262 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 446ms/step - accuracy: 0.5901 - loss: 1.1117 - val_accuracy: 0.1986 - val_loss: 23.2822 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 421ms/step - accuracy: 0.6180 - loss: 1.0148 - val_accuracy: 0.3961 - val_loss: 3.4084 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 425ms/step - accuracy: 0.6695 - loss: 0.8943 - val_accuracy: 0.2575 - val_loss: 10.9275 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 442ms/step - accuracy: 0.6966 - loss: 0.8235 - val_accuracy: 0.5067 - val_loss: 2.0123 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 418ms/step - accuracy: 0.7333 - loss: 0.7669 - val_accuracy: 0.4456 - val_loss: 2.8223 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 440ms/step - accuracy: 0.7610 - loss: 0.6756 - val_accuracy: 0.4914 - val_loss: 3.0959 - learning_rate: 0.0010\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 87ms/step - accuracy: 0.6294 - loss: 1.2648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 53.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/train.npz'\n",
        "test_data_path = '/content/drive/MyDrive/test.npz'\n",
        "\n",
        "train_data = np.load(train_data_path)\n",
        "test_data = np.load(test_data_path)\n",
        "\n",
        "X_train, y_train = train_data['data'], train_data['labels']\n",
        "X_test, y_test = test_data['data'], test_data['labels']\n",
        "\n",
        "print(\"Train data shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "input_shape = (64, 64, X_train.shape[-1])\n",
        "X_train_resized = np.array([tf.image.resize(img, input_shape[:2]).numpy() for img in X_train])\n",
        "X_test_resized = np.array([tf.image.resize(img, input_shape[:2]).numpy() for img in X_test])\n",
        "\n",
        "X_train_resized = X_train_resized / 255.0\n",
        "X_test_resized = X_test_resized / 255.0\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train_resized)\n",
        "\n",
        "#Модель CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(y_train)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "#обучение\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_resized, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model.fit(datagen.flow(X_train_final, y_train_final, batch_size=32),\n",
        "                    epochs=30,\n",
        "                    validation_data=datagen.flow(X_val, y_val, batch_size=32),\n",
        "                    callbacks=[early_stopping, lr_scheduler])\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test_resized, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "model.save('/content/drive/MyDrive/CNN_or_s.h5')\n",
        "\n",
        "def load_model(model_path):\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "loaded_model = load_model('/content/drive/MyDrive/CNN_or_s.h5')\n",
        "\n",
        "#оценка\n",
        "loaded_test_loss, loaded_test_accuracy = loaded_model.evaluate(X_test_resized, y_test)\n",
        "print(f\"Loaded Model Test Accuracy: {loaded_test_accuracy * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2F6F_YJTgCS",
        "outputId": "954cdefd-e443-4286-f51c-05592604b42f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train data shape: (18000, 224, 224, 3) (18000,)\n",
            "Test data shape: (4500, 224, 224, 3) (4500,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 455ms/step - accuracy: 0.1961 - loss: 3.9852 - val_accuracy: 0.1689 - val_loss: 3.2401 - learning_rate: 1.0000e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 445ms/step - accuracy: 0.3153 - loss: 2.3238 - val_accuracy: 0.4642 - val_loss: 1.5159 - learning_rate: 1.0000e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 442ms/step - accuracy: 0.3742 - loss: 1.8292 - val_accuracy: 0.4853 - val_loss: 1.4744 - learning_rate: 1.0000e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 421ms/step - accuracy: 0.3988 - loss: 1.6906 - val_accuracy: 0.5083 - val_loss: 1.4335 - learning_rate: 1.0000e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 428ms/step - accuracy: 0.4122 - loss: 1.5894 - val_accuracy: 0.5017 - val_loss: 1.4484 - learning_rate: 1.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 422ms/step - accuracy: 0.4410 - loss: 1.4987 - val_accuracy: 0.5119 - val_loss: 1.4487 - learning_rate: 1.0000e-05\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.6859 - loss: 0.9139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 49.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - accuracy: 0.6859 - loss: 0.9139\n",
            "Loaded Model Test Accuracy: 49.64%\n"
          ]
        }
      ]
    }
  ]
}